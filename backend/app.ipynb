{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer=GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model=GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(text):\n",
    "    encoded_input= tokenizer.encode(text, add_special_tokens=False, return_tensors='pt')\n",
    "    input_ids=encoded_input[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs=model(input_ids)\n",
    "        logits=outputs.logits\n",
    "\n",
    "\n",
    "    perplexity = torch.exp(torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), input_ids.view(-1)))\n",
    "\n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_burstiness(text):\n",
    "    tokens=nltk.word_tokenize(text.lower())\n",
    "    word_freq=FreqDist(tokens)\n",
    "\n",
    "    repeated_count=sum(count>1 for count in word_freq.values())\n",
    "\n",
    "    burstiness_score=repeated_count/len(word_freq)\n",
    "\n",
    "    return burstiness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16968.384765625\n",
      "0.3150684931506849\n",
      "human content\n"
     ]
    }
   ],
   "source": [
    "text=\"We are building a community for content writers where they can showcase their work and writings without any need to prove their authenticity. Our platform will help content writers showcase their work by providing a badge of trust that highlights that their content is plagiarism-free and has not been copied from some other place. We will provide the content writers with a certificate to attach to their work after they get their content scanned by us and it passes the authenticity check. We are also providing a marketplace where content writers can list down their content which is approved by us and get the opportunity to meet business owners that will no longer have to worry about the writers being honest.\"\n",
    "\n",
    "p=calculate_perplexity(text)\n",
    "b=calculate_burstiness(text)\n",
    "\n",
    "print(p)\n",
    "print(b)\n",
    "\n",
    "if(p>30000 and b<0.2):\n",
    "    print(\"Ai generated content\")\n",
    "else:\n",
    "    print('human content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
